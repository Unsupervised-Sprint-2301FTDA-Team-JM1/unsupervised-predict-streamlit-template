{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 1          item: 31         r_ui = None   est = 3.05   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv('resources/data/movies.csv',sep = ',')\n",
    "ratings_df = pd.read_csv('resources/data/ratings.csv')\n",
    "ratings_df.drop(['timestamp'], axis=1,inplace=True)\n",
    "ratings_df.head()\n",
    "\n",
    "model=pickle.load(open('resources/models/algo.pkl', 'rb'))\n",
    "\n",
    "print(model.predict(1,31))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Script dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "from surprise import Reader, Dataset\n",
    "from surprise import SVD, NormalPredictor, BaselineOnly, KNNBasic, NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Importing data\n",
    "movies_df = pd.read_csv('resources/data/movies.csv',sep = ',')\n",
    "ratings_df = pd.read_csv('resources/data/ratings.csv')\n",
    "ratings_df.drop(['timestamp'], axis=1,inplace=True)\n",
    "\n",
    "# We make use of an SVD model trained on a subset of the MovieLens 10k dataset.\n",
    "model=pickle.load(open('resources/models/algo.pkl', 'rb'))\n",
    "\n",
    "def prediction_item(item_id):\n",
    "    \"\"\"Map a given favourite movie to users within the\n",
    "       MovieLens dataset with the same preference.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    item_id : int\n",
    "        A MovieLens Movie ID.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        User IDs of users with similar high ratings for the given movie.\n",
    "\n",
    "    \"\"\"\n",
    "    # Data preprosessing\n",
    "    reader = Reader(rating_scale=(0, 5))\n",
    "    load_df = Dataset.load_from_df(ratings_df,reader)\n",
    "    a_train = load_df.build_full_trainset()\n",
    "\n",
    "    predictions = []\n",
    "    for ui in a_train.all_users():\n",
    "        predictions.append(model.predict(iid=item_id,uid=ui, verbose = False))\n",
    "    return predictions\n",
    "\n",
    "def pred_movies(movie_list):\n",
    "    \"\"\"Maps the given favourite movies selected within the app to corresponding\n",
    "    users within the MovieLens dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    movie_list : list\n",
    "        Three favourite movies selected by the app user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        User-ID's of users with similar high ratings for each movie.\n",
    "\n",
    "    \"\"\"\n",
    "    # Store the id of users\n",
    "    id_store=[]\n",
    "    # For each movie selected by a user of the app,\n",
    "    # predict a corresponding user within the dataset with the highest rating\n",
    "    for i in movie_list:\n",
    "        predictions = prediction_item(item_id = i)\n",
    "        predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "        # Take the top 10 user id's from each movie with highest rankings\n",
    "        for pred in predictions[:100]:\n",
    "            id_store.append(pred.uid)\n",
    "    # Return a list of user id's\n",
    "    return id_store\n",
    "\n",
    "# !! DO NOT CHANGE THIS FUNCTION SIGNATURE !!\n",
    "# You are, however, encouraged to change its content.  \n",
    "def collab_model(movie_list,top_n=10):\n",
    "    \"\"\"Performs Collaborative filtering based upon a list of movies supplied\n",
    "       by the app user.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    movie_list : list (str)\n",
    "        Favorite movies chosen by the app user.\n",
    "    top_n : type\n",
    "        Number of top recommendations to return to the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list (str)\n",
    "        Titles of the top-n movie recommendations to the user.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    indices = pd.Series(movies_df['title'])\n",
    "    movie_ids = pred_movies(movie_list)\n",
    "\n",
    "    df_init_users = ratings_df[ratings_df['userId']==movie_ids[0]]\n",
    "    # df_init_users = ratings_df\n",
    "    for i in movie_ids :\n",
    "        # df_init_users=df_init_users.append(ratings_df[ratings_df['userId']==i])\n",
    "        df_init_users = pd.concat([df_init_users,ratings_df[ratings_df['userId']==i]])\n",
    "    # Getting the cosine similarity matrix\n",
    "    cosine_sim = cosine_similarity(np.array(df_init_users), np.array(df_init_users))\n",
    "    idx_1 = indices[indices == movie_list[0]].index[0]\n",
    "    idx_2 = indices[indices == movie_list[1]].index[0]\n",
    "    idx_3 = indices[indices == movie_list[2]].index[0]\n",
    "    print(idx_1,idx_2,idx_3,\"lol\",len(cosine_sim))\n",
    "    # Creating a Series with the similarity scores in descending order\n",
    "    rank_1 = cosine_sim[idx_1]\n",
    "    rank_2 = cosine_sim[idx_2]\n",
    "    rank_3 = cosine_sim[idx_3]\n",
    "    # Calculating the scores\n",
    "    score_series_1 = pd.Series(rank_1).sort_values(ascending = False)\n",
    "    score_series_2 = pd.Series(rank_2).sort_values(ascending = False)\n",
    "    score_series_3 = pd.Series(rank_3).sort_values(ascending = False)\n",
    "    \n",
    "    # Appending the names of movies\n",
    "    # listings = score_series_1.append(score_series_1).append(score_series_3).sort_values(ascending = False)\n",
    "    listings = pd.concat([score_series_1,score_series_2,score_series_3])\n",
    "    recommended_movies = []\n",
    "    # Choose top 50\n",
    "    top_50_indexes = list(listings.iloc[1:50].index)\n",
    "    # Removing chosen movies\n",
    "    top_indexes = np.setdiff1d(top_50_indexes,[idx_1,idx_2,idx_3])\n",
    "    for i in top_indexes[:top_n]:\n",
    "        recommended_movies.append(list(movies_df['title'])[i])\n",
    "    return recommended_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 68 288 lol 45106\n",
      "['Unzipped (1995)', 'Go Fish (1994)', 'Alien Escape (1995)', 'Twilight (1998)', 'Fitzcarraldo (1982)', 'Born Yesterday (1950)', 'Me, Myself & Irene (2000)', 'Couch in New York, A (1996)', 'Pledge, The (2001)', \"How I Killed My Father (a.k.a. My Father and I) (Comment j'ai tué mon Père) (2001)\"]\n",
      "(0, 'Unzipped (1995)')\n",
      "(1, 'Go Fish (1994)')\n",
      "(2, 'Alien Escape (1995)')\n",
      "(3, 'Twilight (1998)')\n",
      "(4, 'Fitzcarraldo (1982)')\n",
      "(5, 'Born Yesterday (1950)')\n",
      "(6, 'Me, Myself & Irene (2000)')\n",
      "(7, 'Couch in New York, A (1996)')\n",
      "(8, 'Pledge, The (2001)')\n",
      "(9, \"How I Killed My Father (a.k.a. My Father and I) (Comment j'ai tué mon Père) (2001)\")\n"
     ]
    }
   ],
   "source": [
    "Lists = [\"Grumpier Old Men (1995)\",\"Friday (1995)\",\"Outbreak (1995)\"]\n",
    "List = [\"Jumanji (1995)\",\"Skylark (1941)\",\"Sabotage (2014)\"] \n",
    "top = collab_model(movie_list=Lists)\n",
    "print(top)\n",
    "for i in enumerate(top):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
